<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Meghna Kapoor</title>
  
  <meta name="author" content="Meghna Kapoor">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> 
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Meghna Kapoor</name>
              </p>
              <p>I am a Ph.D. Research Scholar under the supervision of <a target="_blank" href="https://sites.google.com/view/badrisubudhi/home?pli=1">Dr. Badri N Subudhi</a> and <a target="_blank" href="https://www.iitjammu.ac.in/faculty/~ankurbansal">Dr. Ankur Bansal</a> in the EE Department at <a target="_blank" href="https://www.iitjammu.ac.in/">Indian Institute of Technology Jammu, India</a> since 2021. I primarily work in the area of image processing, computer vision, graph learning, and underwater surveillance. 
              </p>
              <p>
                I have completed my M.E. in Electronics and Communication from <a target="_blank" href="https://www.thapar.edu/">Thapar Institute of Engineering and Technology</a> Patiala, India.



              </p>
		    
		<!------------------------------IDs--------------------------------->	
              <p style="text-align:center">
                <a target="_blank" href="mailto:meghna@iitjammu.ac.in">Email</a> &nbsp/&nbsp
                <a target="_blank" href="https://scholar.google.com/citations?user=q9jVEqkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a target="_blank" href="https://www.linkedin.com/in/meghna-kapoor-166b15147/">Linkedin</a> &nbsp/&nbsp
                <a target="_blank" href="https://drive.google.com/file/d/19CaVkDZujsJUKVyG_r2GmywAG2fpF-rY/view?usp=sharing">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/meghna_2020REE2058.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/meghna_2020REE2058.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


		
		<!------------------------------News--------------------------------->	
	 <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
		    <p> 09/01/2024 - One paper accepted in the Journal of Computer Vision and Image Understanding. Congratulations  <a target="_blank" href="https://sites.google.com/view/wiekeprummel/">Wieke Prummel</a> ! 
		<p> 21/12/2024 - One paper accepted in the International Conference on Acoustics, Speech, and Signal Processing 2025 </p>
		<p> 17/08/2024 - One paper accepted in the International Conference on Pattern Recognition 2024.</p>
		<p> 06/06/2024 - One paper accepted in Ocean Engineering </p>
		<p> 20/08/2023 - Received ‚Ç¨1000 travel grant for ICCV 2023 </p>
		<p> 07/08/2023 - One paper accepted in International conference on computer vision workshops 2023 </p>
		<p> 02/05/2023 - Received 1400 USD Travel award for CVPR 2023 </p> 
		<p> 06/04/2023 - One paper accepted in Computer Vision Workshops 2023 </p>
		<p> 08/12/2021 - Awarded Prime Minister's fellowship scheme for doctoral research  </p>
		<p> 15/01/2021 - Started PhD in the domain of underwater surveillance </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
		<tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
		      I am currently engaged in the field of underwater surveillance, focusing on mitigating degradations in complex underwater environments. My work involves implementing various methodologies to enhance image clarity, preserve details, and accurately detect objects in challenging underwater conditions.
	      </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

		<!------------------------------Paper 6--------------------------------->	
		     <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
               
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Graph-based Moving Object Segmentation for Underwater Videos using Semi-supervised Learning</papertitle>
              </a>
              <br>
         <a target="_blank" href="https://immkapoor.github.io/website/">Meghna Kapoor</a>, 
		   <a target="_blank" href="https://sites.google.com/view/wiekeprummel/">Wieke Prummel</a>, 
		   <a target="_blank" href="https://jhonygiraldo.github.io/">Jhony Giraldo</a>, 
	<a target="_blank" href="https://sites.google.com/view/badrisubudhi/home?pli=1">Badri N Subudhi</a>,
		   <a target="_blank" href="https://ieeexplore.ieee.org/author/37085571642">Anastasia Zakharova</a>,
		   <a target="_blank" href="https://sites.google.com/site/thierrybouwmans/">Thierry Bouwmans</a>, 
		 <a target="_blank" href="https://www.iitjammu.ac.in/faculty/~ankurbansal">Ankur Bansal </a>
              <em></sup>Computer Vision and Image Understanding</em>, 2025.
              <br>
              <p></p>
              <p>
we propose a semi-supervised graph-learning approach (GraphMOS-U) to segment moving objects in underwater environments. </p>            </td>
          </tr>
		
		<!------------------------------Paper 5--------------------------------->	
			
         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img style="width: 160px;" src='images/hypergraph_refactoring.png'>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Graph Refinement in Latent Space: A Hypergraph Convolution for Underwater Object Detection</papertitle>
              </a>
              <br>
         <a target="_blank" href="https://immkapoor.github.io/website/">Meghna Kapoor</a>, 
	<a target="_blank" href="https://sites.google.com/view/badrisubudhi/home?pli=1">Badri N Subudhi</a>,
		 <a target="_blank" href="https://www.iitjammu.ac.in/faculty/~ankurbansal">Ankur Bansal </a>
              <em></sup>in Proceedings of the International Conference on Acoustic, Speech, and Signal Processing, Hyderabad, India</em>, 2024.
              <br>
              <p></p>
              <p>
The proposed approach uses a convolutional backbone to project the image into latent space, where an unsupervised initial graph is constructed. The hypergraph convolution is then utilized to optimize message passing between graph nodes, enhancing the representation of complex relationships of latent space. This helps in the retention of intricate details by modelling two or more latent variables as hyperedge by sharing the information among themselves. Finally, an image generation module maps the enhanced graph representation back to image space. </p>            </td>
          </tr>
		
		<!------------------------------Paper 4--------------------------------->	
			
         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img style="width: 160px;" src='images/PNA_arch.jpg'>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
		 <a target="_blank" href="https://link.springer.com/chapter/10.1007/978-3-031-78110-0_26">
                <papertitle>Principal Graph Neighborhood Aggregation for Underwater Moving Object Detection</papertitle>
              </a>
              <br>
         <a target="_blank" href="https://immkapoor.github.io/website/">Meghna Kapoor</a>, 
	<a target="_blank" href="https://sites.google.com/view/badrisubudhi/home?pli=1">Badri N Subudhi</a>,
	<a target="_blank" href="https://sites.google.com/view/vinitjakhetiya/home">Vinit Jakhetiya</a>,
		 <a target="_blank" href="https://www.iitjammu.ac.in/faculty/~ankurbansal">Ankur Bansal </a>
              <em></sup>in Proceedings of the International Conference on Pattern Recognition (ICPR), Kolkata, India</em>, 2024.
              <br>
	      <a target="_blank" href="https://link.springer.com/chapter/10.1007/978-3-031-78110-0_26">Paper Link</a>
              <p></p>
              <p>
                This study presents an end-to-end moving object detection architecture to analyze intricate underwater scenes. We adhered to a ResNet-50 backbone in the proposed architecture to project the video frame to feature space. Graph learning is used to retain the structural information of the object by projecting from feature space to graph space. Multiple aggregators facilitate the seamless transfer of information among neighbouring nodes, alleviating noise induced by deep architectures. The refactored latent vector is transformed to image space to detect the moving object(s) from the given scene. </p>
            </td>
          </tr>
          
		<!------------------------------Paper 3--------------------------------->
		
         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img style="width: 160px;" src='images/paper3.jpg'>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0029801824017050">
                <papertitle>Underwater visual surveillance: A comprehensive survey</papertitle>
              </a>
              <br>
	<a target="_blank" href="https://scholar.google.co.in/citations?user=EZC07FoAAAAJ&hl=en">Deepak Kumar Rout</a>, 
        <a target="_blank" href="https://immkapoor.github.io/website/">Meghna Kapoor</a>, 
	<a target="_blank" href="https://iitjammu.ac.in/electrical_engineering/faculty-list/~badrinsubudhi">Badri N Subudhi</a>,
	<a target="_blank" href="https://nitgoa.ac.in/People/frontend/veerakumar.html">T Veerakumar</a>,	    
	<a target="_blank" href="https://sites.google.com/view/vinitjakhetiya/home">Vinit Jakhetiya</a>,
	<a target="_blank" href="https://www.iitjammu.ac.in/faculty/~ankurbansal">Ankur Bansal </a>

		    <em></sup>in Ocean Engineering</em>, 2024.
              <br>
              <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0029801824017050">Paper Link</a>
              <p></p>
              <p>
               The objective of this article is to provide a detailed review of the state-of-the-art underwater surveillance process and the new trends of the same. Underwater surveillance has recently gotten lots of attention because of its potential applications including the security of the coastal border, effective fish farming, deep-sea exploration, preservation of rare aquatic animals, etc.</p>
            </td>
          </tr>
          <!---------------------------Paper 2------------------------------------>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img style="width: 160px;" src='images/corrected_diagram.png'>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank"  href="https://openaccess.thecvf.com/content/ICCV2023W/WiCV/papers/Kapoor_Domain_Adversarial_Learning_Towards_Underwater_Image_Enhancement_ICCVW_2023_paper.pdf">
                <papertitle>Domain Adversarial Learning Towards Underwater Image Enhancement</papertitle>
              </a>
              <br>
         <a target="_blank" href="https://immkapoor.github.io/website/">Meghna Kapoor</a>, 
         <a target="_blank" href="https://www.linkedin.com/in/rohan-baghel-40360b1a4/?originalSubdomain=in">Rohan Baghel</a>, 
	<a target="_blank" href="https://sites.google.com/view/badrisubudhi/home?pli=1">Badri N Subudhi</a>,
	<a target="_blank" href="https://sites.google.com/view/vinitjakhetiya/home">Vinit Jakhetiya</a>,
		 <a target="_blank" href="https://www.iitjammu.ac.in/faculty/~ankurbansal">Ankur Bansal </a>

        
              <em>in Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops</em>, 2023
              <br>
              <a target="_blank" href="https://openaccess.thecvf.com/content/ICCV2023W/WiCV/papers/Kapoor_Domain_Adversarial_Learning_Towards_Underwater_Image_Enhancement_ICCVW_2023_paper.pdf">Paper Link</a>
              <p></p>
	      <p>
		 This paper proposes an encoder-decoder network that preserves the image content, texture, and style while maintaining overall global similarity by capturing the inherent distribution of the training samples. To overcome the deviation due to a change in water type, a classifier network is induced in the latent space of encoder-decoder architecture. The classifier loss and adversarial loss in the classifier network ensure the learning across domains and avoid setting priors on captured distribution. Hence, the proposed model is robust against the change of water type and can be deployed in real-life without re-training. </p>
	    </td>
        </tr>
 <!---------------------------Paper 1------------------------------------>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img style="width: 160px;" src='images/Basic_GraphSage.png'>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2023W/WiCV/html/Kapoor_Underwater_Moving_Object_Detection_Using_an_End-to-End_Encoder-Decoder_Architecture_and_CVPRW_2023_paper.html">
                <papertitle>Underwater Moving Object Detection Using an End-to-End Encoder-Decoder Architecture and GraphSage With Aggregator and Refactoring</papertitle>
              </a>
              <br>
     <a target="_blank" href="https://immkapoor.github.io/website/">Meghna Kapoor</a>, 
         <a target="_blank" href="https://www.linkedin.com/in/suvam-patra/">Suvam Patra</a>, 
	<a target="_blank" href="https://sites.google.com/view/badrisubudhi/home?pli=1">Badri N Subudhi</a>,
	<a target="_blank" href="https://sites.google.com/view/vinitjakhetiya/home">Vinit Jakhetiya</a>,
		 <a target="_blank" href="https://www.iitjammu.ac.in/faculty/~ankurbansal">Ankur Bansal </a>

        
              <em>in Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops</em>, 2023
              <br>
              <a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2023W/WiCV/html/Kapoor_Underwater_Moving_Object_Detection_Using_an_End-to-End_Encoder-Decoder_Architecture_and_CVPRW_2023_paper.html">Paper Link</a>
              <p></p>
	      <p>
 We propose a unique architecture for underwater object detection where U-Net architecture is considered with the ResNet-50 backbone. Further, the latent space features from the encoder are fed to the decoder through a GraphSage model. GraphSage-based model is explored to reweight the node relationship in non-euclidean space using different aggregator functions and hence characterize the spatio-contextual bonding among the pixels. Further, we explored the dependency on different aggregator functions: mean, max, and LSTM, to evaluate the model's performance.	</td>
       </p>
	  </tr>





          </tr>				
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <p style="text-align:right;font-size:small;">
                Thanks for Visiting my Page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <p style="text-align:right;font-size:small;">
		  <!-- hitwebcounter Code START -->
<a href="https://www.hitwebcounter.com" target="_blank">
<img src="https://hitwebcounter.com/counter/counter.php?page=17673767&style=0001&nbdigits=1&type=page&initCount=0" title="Counter Widget" Alt="Visit counter For Websites"   border="0" /></a>                                    
               </p>
            </td>
                                 
                                        
          </tr>
        </tbody></table>
</body>

</html>
